# ğŸš€ Pseudocode2Cpp â€“ Transformer-based Pseudocode to C++ Converter

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Hugging Face](https://img.shields.io/badge/HuggingFace-Spaces-orange)](https://huggingface.co/spaces/asadsandhu/Pseudocode2Cpp)
[![GitHub Repo](https://img.shields.io/badge/GitHub-asadsandhu/Pseudocode2Cpp-black?logo=github)](https://github.com/asadsandhu/Pseudocode2Cpp)

> A fully custom Transformer-based Sequence-to-Sequence model built from scratch in PyTorch to convert human-written pseudocode into executable C++ code. Trained on the [SPoC dataset](https://arxiv.org/abs/2005.04326) from Stanford.

---

## ğŸ–¼ï¸ Demo

Try it live on **Hugging Face Spaces**:  
ğŸ‘‰ https://huggingface.co/spaces/asadsandhu/Pseudocode2Cpp

![App Demo](assets/demo.png)

---

## ğŸ§  Model Architecture

- Developed using the **Transformer** architecture from scratch in PyTorch
- No pre-trained models (pure from-scratch implementation)
- Token-level sequence generation using greedy decoding
- Custom vocabulary construction for both pseudocode and C++ output

```

Input:   Pseudocode lines (line-by-line)
Model:   Transformer (Encoder-Decoder)
Output:  C++ code line for each pseudocode line

```

---

## ğŸ“Š Dataset

We used the **SPoC dataset** from Stanford:

- âœ… Clean pseudocodeâ€“C++ line pairs
- âœ… Token-level annotations for syntax handling
- âœ… Multiple test splits (generalization to problems/workers)
- âœ… Custom preprocessing and vocabulary building implemented

> ğŸ“ Licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)

---

## ğŸ“ Directory Structure

```

.
â”œâ”€â”€ app.py                # Gradio web app for inference
â”œâ”€â”€ train.py              # Transformer training code
â”œâ”€â”€ model.pth             # Trained model weights
â”œâ”€â”€ spoc/                 # Dataset directory
â”‚   â””â”€â”€ train/
â”‚       â”œâ”€â”€ spoc-train.tsv
â”‚       â””â”€â”€ split/spoc-train-eval.tsv
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ demo.png          # App screenshot
â””â”€â”€ README.md             # You're here

````

---

## ğŸ› ï¸ How to Run Locally

### âš™ï¸ 1. Clone Repo & Install Requirements

```bash
git clone https://github.com/asadsandhu/Pseudocode2Cpp.git
cd Pseudocode2Cpp
pip install -r requirements.txt
````

Or manually install:

```bash
pip install torch gradio tqdm
```

### ğŸš€ 2. Launch the App

Make sure `model.pth` is present (or train using `train.py`):

```bash
python app.py
```

The app will open in your browser.

---

## ğŸ§ª Training the Model

You can retrain the model using the `train.py` script:

```bash
python train.py
```

By default, it downloads data from the public repo and trains for 10 epochs.
Outputs a `model.pth` file with learned weights and vocab.

---

## ğŸ”§ Key Hyperparameters

| Parameter      | Value       |
| -------------- | ----------- |
| Model Type     | Transformer |
| Max Length     | 128         |
| Embedding Dim  | 256         |
| FFN Dim        | 512         |
| Heads          | 4           |
| Encoder Layers | 2           |
| Decoder Layers | 2           |
| Batch Size     | 64          |
| Epochs         | 10          |
| Optimizer      | Adam        |
| Learning Rate  | 1e-4        |

---

## ğŸ§© Example Input

```text
Declare variable i and set it to 0
Repeat while i is less than 10
Print i
Increment i by 1
```

### â© Output C++

```cpp
int main() {
int i = 0;
while (i < 10) {
std::cout << i << std::endl;
i = i + 1;
}
return 0;
}
```

---

## ğŸ“¦ Deployment

This app is deployed live on:

* **Hugging Face Spaces**: [Pseudocode2Cpp](https://huggingface.co/spaces/asadsandhu/Pseudocode2Cpp)
* **GitHub**: [github.com/asadsandhu/Pseudocode2Cpp](https://github.com/asadsandhu/Pseudocode2Cpp)

---

## ğŸ™Œ Acknowledgements

* ğŸ“˜ **SPoC Dataset** by Stanford University
  Kulal, S., Pasupat, P., & Liang, P. (2020). [SPoC: Search-based Pseudocode to Code](https://arxiv.org/abs/2005.04326)

* ğŸ§  Transformer Paper: ["Attention is All You Need"](https://arxiv.org/abs/1706.03762)

---

## ğŸ§‘â€ğŸ’» Author

**Asad Ali**
[GitHub: asadsandhu](https://github.com/asadsandhu)
[Hugging Face: asadsandhu](https://huggingface.co/asadsandhu)
[LinkedIn: asadxali](https://www.linkedin.com/in/asadxali)

---

## ğŸ“„ License

This project is licensed under the MIT License.
Feel free to use, modify, and share with credit.
